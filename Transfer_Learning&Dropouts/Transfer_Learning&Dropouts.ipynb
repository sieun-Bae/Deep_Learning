{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning&Dropouts.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4fLPqqU1VID",
        "colab_type": "text"
      },
      "source": [
        "# Transfer_learning&Dropouts\n",
        "In this lab you will work through transfer learning using the Inception (version3) network for classifying cats and dogs.\n",
        "\n",
        "---\n",
        "\n",
        "### A. Transfer Learning\n",
        "Model definition: the code cell below does the following:\n",
        "\n",
        "1. Downloads the weights for a pre-trained inception network, and then instantiates a new instance of it using those weights.\n",
        "2. Selects one of the pre-trained convolutional layers as the last layer for our new model to take as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc2ce14d-22a1-4f6c-f05b-c10210d3da31"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# 1. downloads the weights for a pre-trained inception\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Uncomment the code below to see the (huge) model summary  \n",
        "pre_trained_model.summary()\n",
        "\n",
        "# 2. \n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape) #(None, 7, 7, 768)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--2019-11-11 03:43:27--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  18.5MB/s    in 4.5s    \n",
            "\n",
            "2019-11-11 03:43:32 (18.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyM9jFYE2vzB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Adding layers and compiling model\n",
        "3. Add a fully connected layer to the pre-trained layers that have been defined as input to our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# 3.1 Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# 3.2 Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "# For Part C: (Do this after completing 9) 10. Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# 3.3 Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxmxyOJC3LXc",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation\n",
        "4. Download cats vs dogs data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c5af4658-5a6f-4321-d592-4d4a29edf1c4"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# For Part B: (Do this after completing 6) 7. Add data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255.,\n",
        "    rotation_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        "    ) \n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-11 03:57:20--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  69%[============>       ]  45.35M   227MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   234MB/s    in 0.3s    \n",
            "\n",
            "2019-11-11 03:57:20 (234 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SILt-VOe5H3M",
        "colab_type": "text"
      },
      "source": [
        "### Training\n",
        "5. Train the model consisting of pre-trained layers from Inception v3 and new layers defined in 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a69203b2-58d2-48be-ba0b-fe3054d78865"
      },
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 1/20\n",
            "100/100 - 26s - loss: 0.4858 - acc: 0.7685 - val_loss: 0.3026 - val_acc: 0.9050\n",
            "Epoch 2/20\n",
            "Epoch 1/20\n",
            "100/100 - 23s - loss: 0.3276 - acc: 0.8555 - val_loss: 0.3870 - val_acc: 0.9110\n",
            "Epoch 3/20\n",
            "Epoch 1/20\n",
            "100/100 - 21s - loss: 0.3153 - acc: 0.8700 - val_loss: 0.4556 - val_acc: 0.9140\n",
            "Epoch 4/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.2781 - acc: 0.8880 - val_loss: 0.7022 - val_acc: 0.9000\n",
            "Epoch 5/20\n",
            "Epoch 1/20\n",
            "100/100 - 21s - loss: 0.2715 - acc: 0.8950 - val_loss: 0.3139 - val_acc: 0.9470\n",
            "Epoch 6/20\n",
            "Epoch 1/20\n",
            "100/100 - 21s - loss: 0.2609 - acc: 0.8980 - val_loss: 0.3758 - val_acc: 0.9390\n",
            "Epoch 7/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2347 - acc: 0.9125 - val_loss: 0.4557 - val_acc: 0.9360\n",
            "Epoch 8/20\n",
            "Epoch 1/20\n",
            "100/100 - 21s - loss: 0.2627 - acc: 0.8990 - val_loss: 0.2901 - val_acc: 0.9560\n",
            "Epoch 9/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.2183 - acc: 0.9130 - val_loss: 0.3923 - val_acc: 0.9540\n",
            "Epoch 10/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2226 - acc: 0.9080 - val_loss: 0.2863 - val_acc: 0.9650\n",
            "Epoch 11/20\n",
            "Epoch 1/20\n",
            "100/100 - 23s - loss: 0.2430 - acc: 0.9110 - val_loss: 0.3479 - val_acc: 0.9550\n",
            "Epoch 12/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.2163 - acc: 0.9080 - val_loss: 0.3324 - val_acc: 0.9600\n",
            "Epoch 13/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.2218 - acc: 0.9140 - val_loss: 0.4307 - val_acc: 0.9490\n",
            "Epoch 14/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.1815 - acc: 0.9305 - val_loss: 0.3952 - val_acc: 0.9600\n",
            "Epoch 15/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.2128 - acc: 0.9160 - val_loss: 0.3712 - val_acc: 0.9590\n",
            "Epoch 16/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.1899 - acc: 0.9245 - val_loss: 0.3636 - val_acc: 0.9620\n",
            "Epoch 17/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.1979 - acc: 0.9280 - val_loss: 0.4102 - val_acc: 0.9550\n",
            "Epoch 18/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.2151 - acc: 0.9180 - val_loss: 0.3830 - val_acc: 0.9610\n",
            "Epoch 19/20\n",
            "Epoch 1/20\n",
            "100/100 - 20s - loss: 0.1919 - acc: 0.9240 - val_loss: 0.4207 - val_acc: 0.9540\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "100/100 - 21s - loss: 0.2059 - acc: 0.9190 - val_loss: 0.3632 - val_acc: 0.9610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-KC409T5jHn",
        "colab_type": "text"
      },
      "source": [
        "### Model performance\n",
        "6, 9, 11. Plot the graph of the training and validation accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9aea2f95-6678-4d24-8ca9-fe1b7c7731d2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npgAMwzCilP8Hb/vFxdL2n8AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q91AG4Lal-7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}